#!/usr/bin/env bash
# Replay judge evaluation
# Generated by ProjectScylla E2E test framework

set -euo pipefail

JUDGE_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"

# Re-run Claude CLI with the same prompt and model (shared judge_prompt.md at run level)
claude \
  --model claude-haiku-4-5 \
  --prompt "$JUDGE_DIR/../../judge_prompt.md" \
  > "$JUDGE_DIR/response.txt"

echo "Judge response saved to $JUDGE_DIR/response.txt"
