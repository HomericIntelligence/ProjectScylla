% BibTeX References for ProjectScylla Research
% Generated: 2026-02-07
% Contains only cited references from paper.tex

% =============================================================================
% Core Benchmark and Framework References
% =============================================================================

@inproceedings{liu2023agentbench,
  title={{AgentBench}: Evaluating {LLMs} as Agents},
  author={Liu, Xiao and others},
  booktitle={International Conference on Learning Representations (ICLR)},
  year={2024},
  url={https://arxiv.org/abs/2308.03688},
  note={Multi-turn agent evaluation across operating systems, databases, and knowledge graphs}
}

@article{jimenez2024swebench,
  title={{SWE-bench}: Can Language Models Resolve Real-world Github Issues?},
  author={Jimenez, Carlos E. and others},
  journal={arXiv preprint arXiv:2310.06770},
  year={2024},
  url={https://arxiv.org/abs/2310.06770},
  note={Benchmark for evaluating LLMs on real GitHub issues}
}

@article{yao2024taubench,
  title={{TAU-bench}: A Benchmark for Tool-Augmented {LLMs}},
  author={Yao, Shunyu and others},
  journal={arXiv preprint},
  year={2024},
  url={https://arxiv.org/abs/2406.12045},
  note={Benchmark for evaluating agents' ability to use external tools}
}

@article{zhu2024promptbench,
  title={{PromptBench}: Towards Evaluating the Robustness of Large Language Models on Adversarial Prompts},
  author={Zhu, Kaijie and others},
  journal={arXiv preprint arXiv:2306.04528},
  year={2024},
  url={https://arxiv.org/abs/2306.04528},
  note={Benchmark for prompt evaluation and robustness}
}

@misc{polo2024efficient,
  title={Efficient multi-prompt evaluation of LLMs},
  author={Polo, Felipe Maia and others},
  year={2024},
  howpublished={\url{https://arxiv.org/abs/2405.17202}},
  note={Framework for efficient LLM evaluation}
}

@misc{projectodyssey,
  title={{ProjectOdyssey}: Comprehensive Agent Orchestration Framework},
  author={{Homeric Intelligence}},
  year={2025},
  howpublished={\url{https://github.com/HomericIntelligence/Projectodyssey}},
  note={Accessed: 2025-12-30. Git hash: 011a3ff}
}

@misc{anthropic2024claude,
  title={{Claude Code}: Agentic {CLI} Tool for Software Development},
  author={{Anthropic}},
  year={2024},
  howpublished={\url{https://www.anthropic.com/claude/code}},
  note={AI-powered command-line interface for coding tasks}
}

@misc{gao2024lmevalharness,
  title={{lm-evaluation-harness}: A Framework for Few-Shot Language Model Evaluation},
  author={Gao, Leo and others},
  year={2024},
  howpublished={\url{https://github.com/EleutherAI/lm-evaluation-harness}},
  note={General-purpose LLM evaluation framework}
}

@misc{safetynet,
  title={safety-net: {Claude Code} Plugin for Dangerous Operation Blocking},
  author={{CC-Marketplace}},
  howpublished={\url{https://github.com/cc-marketplace/safety-net}},
  year={2025},
  note={Security plugin for Claude Code CLI}
}

@misc{ccmarketplace,
  author={Anand Tyagi},
  title={{CC-Marketplace}: Community Marketplace for {Claude Code} Plugins and Skills},
  howpublished={\url{https://github.com/cc-marketplace}},
  year={2025},
  note={Community-driven plugin repository}
}
